{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd84acae-19cc-4692-bd93-6e04c75b2af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "CONFIG = {\n",
    "    \"base_dir\": r\"C:/Users/81005/Desktop/CYH/3-PFAS/3.2.4_pathway_analysis/LOO\",\n",
    "    \"base_file\": \"probability_base.xlsx\",\n",
    "    \"inputs_file\": \"inputs_core.xlsx\",\n",
    "\n",
    "    \"pfas_col_candidates\": [\"PFAS_name\", \"PFAS Name\", \"PFAS\", \"Name\"],\n",
    "\n",
    "    \"prob_col_candidates\": {\n",
    "        \"PI3K-AKT\": [\n",
    "            \"P (PI3K – AKT)\",\n",
    "            \"P(PI3K – AKT)\",\n",
    "            \"P (PI3K- AKT)\", \"P (PI3K - AKT)\", \"P(PI3K-AKT)\", \"P (PI3K-AKT)\",\n",
    "            \"Probability of reaching PI3K–AKT pathway\",\n",
    "            \"Probability of reaching PI3K- AKT pathway\",\n",
    "            \"Probability of reaching PI3K-AKT pathway\"\n",
    "        ],\n",
    "        \"PPAR\": [\n",
    "            \"P (PPAR)\", \"P(PPAR)\",\n",
    "            \"P(PPAR signaling)\", \"P (PPAR signaling)\",\n",
    "            \"Probability of reaching PPAR signaling pathway\",\n",
    "            \"Probability of reaching PPAR pathway\"\n",
    "        ],\n",
    "        \"LPS\": [\n",
    "            \"P (LPS)\", \"P(LPS)\", \"Probability of reaching LPS pathway\"\n",
    "        ],\n",
    "        \"ROS\": [\n",
    "            \"P (ROS)\", \"P(ROS)\", \"Probability of reaching ROS pathway\"\n",
    "        ],\n",
    "    },\n",
    "\n",
    "    \"evidence_sheet\": \"evidence\",\n",
    "\n",
    "    \"default_weights\": {\n",
    "        \"weight_FDR\": 1.0,\n",
    "        \"weight_Count\": 1.0,\n",
    "        \"weight_Hub\": 1.0,\n",
    "        \"floor\": 0.02\n",
    "    },\n",
    "\n",
    "    \"out_summary\": \"LOO_summary.xlsx\",\n",
    "    \"out_deltas\": \"LOO_deltas.xlsx\",\n",
    "\n",
    "    \"round_digits\": 6,\n",
    "}\n",
    "\n",
    "def _find_first_col(df: pd.DataFrame, cand_list):\n",
    "    for c in cand_list:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "        c2 = c.strip()\n",
    "        if c2 in df.columns:\n",
    "            return c2\n",
    "        c3 = c.replace(\"–\", \"-\")\n",
    "        if c3 in df.columns:\n",
    "            return c3\n",
    "        c4 = c.replace(\"-\", \"–\")\n",
    "        if c4 in df.columns:\n",
    "            return c4\n",
    "        c5 = c.replace(\" \", \"\")\n",
    "        no_space_cols = {col.replace(\" \", \"\"): col for col in df.columns}\n",
    "        if c5 in no_space_cols:\n",
    "            return no_space_cols[c5]\n",
    "raise ValueError(\n",
    "    f\"None of the following column names were found in the header: {cand_list}\\n\"\n",
    "    f\"Available columns: {list(df.columns)}\"\n",
    ")\n",
    "\n",
    "def _read_base_probs(base_path: str, cfg: dict):\n",
    "    df = pd.read_excel(base_path)\n",
    "    pfas_col = _find_first_col(df, cfg[\"pfas_col_candidates\"])\n",
    "    df.rename(columns={pfas_col: \"__PFAS__\"}, inplace=True)\n",
    "\n",
    "    prob_cols = {}\n",
    "    for key, cand in cfg[\"prob_col_candidates\"].items():\n",
    "        col = _find_first_col(df, cand)\n",
    "        prob_cols[key] = col\n",
    "\n",
    "    return df, prob_cols  \n",
    "\n",
    "def _read_weights_or_default(inputs_path: str, default_w: dict):\n",
    "    try:\n",
    "        wdf = pd.read_excel(inputs_path, sheet_name=\"weights\")\n",
    "        row = wdf.iloc[0].to_dict()\n",
    "        out = default_w.copy()\n",
    "        out[\"weight_FDR\"]   = float(row.get(\"weight_FDR\",   out[\"weight_FDR\"]))\n",
    "        out[\"weight_Count\"] = float(row.get(\"weight_Count\", out[\"weight_Count\"]))\n",
    "        out[\"weight_Hub\"]   = float(row.get(\"weight_Hub\",   out[\"weight_Hub\"]))\n",
    "        out[\"floor\"]        = float(row.get(\"floor\",        out[\"floor\"]))\n",
    "        return out\n",
    "    except Exception:\n",
    "        return default_w.copy()\n",
    "\n",
    "def _canon_path_name(x: str) -> str:\n",
    "    if not isinstance(x, str):\n",
    "        x = str(x)\n",
    "    s = x.strip().upper().replace(\"–\", \"-\")\n",
    "\n",
    "    if s in (\"PI3K\", \"PI3K-AKT\", \"PI3K - AKT\"):\n",
    "        return \"PI3K-AKT\"\n",
    "    if s in (\"PPAR\",):\n",
    "        return \"PPAR\"\n",
    "    if s in (\"LPS\",):\n",
    "        return \"LPS\"\n",
    "    if s in (\"ROS\",):\n",
    "        return \"ROS\"\n",
    "    return s \n",
    "\n",
    "def _read_evidence(inputs_path: str, evidence_sheet: str):\n",
    "    ev = pd.read_excel(inputs_path, sheet_name=evidence_sheet)\n",
    "\n",
    "    rename_map = {}\n",
    "    for k in ev.columns:\n",
    "        k2 = k.strip()\n",
    "        if k2.lower() in (\"path\", \"term\"):\n",
    "            rename_map[k] = \"path\"\n",
    "        elif k2.lower() in (\"fdr\", \"w_fdr\"):\n",
    "            rename_map[k] = \"FDR\"\n",
    "        elif k2.lower() in (\"count\", \"w_count\"):\n",
    "            rename_map[k] = \"Count\"\n",
    "        elif k2.lower() in (\"hub\", \"w_hub\"):\n",
    "            rename_map[k] = \"Hub\"\n",
    "    ev = ev.rename(columns=rename_map)\n",
    "\n",
    "required = [\"path\", \"FDR\", \"Count\", \"Hub\"]\n",
    "for r in required:\n",
    "    if r not in ev.columns:\n",
    "        raise ValueError(\n",
    "            f\"Evidence table is missing required columns: {required}; \"\n",
    "            f\"current columns: {list(ev.columns)}\"\n",
    "        )\n",
    "\n",
    "ev[\"path\"] = ev[\"path\"].apply(_canon_path_name)\n",
    "\n",
    "ev = ev[ev[\"path\"].isin([\"PI3K-AKT\", \"PPAR\", \"LPS\", \"ROS\"])].copy()\n",
    "if ev.empty:\n",
    "    raise ValueError(\n",
    "        \"The evidence table does not contain rows for PI3K-AKT / PPAR / LPS / ROS.\"\n",
    "    )\n",
    "\n",
    "\n",
    "    ev = ev.set_index(\"path\")[[\"FDR\", \"Count\", \"Hub\"]]\n",
    "    ev = ev.astype(float)\n",
    "    return ev \n",
    "\n",
    "def _calc_path_score(F, C, H, wf, wc, wh):\n",
    "    return (wf*F + wc*C + wh*H) / (wf + wc + wh)\n",
    "\n",
    "def _calc_r_after_drop(F, C, H, drop_key, wf, wc, wh):\n",
    "\n",
    "    w = {\"FDR\": wf, \"Count\": wc, \"Hub\": wh}\n",
    "    w[drop_key] = 0.0\n",
    "    s = w[\"FDR\"] + w[\"Count\"] + w[\"Hub\"]\n",
    "    if s == 0:\n",
    "        return 1.0\n",
    "    w_norm = {k: v/s for k, v in w.items()} \n",
    "    score_loo  = w_norm[\"FDR\"]*F + w_norm[\"Count\"]*C + w_norm[\"Hub\"]*H\n",
    "    score_base = _calc_path_score(F, C, H, wf, wc, wh)\n",
    "    if score_base == 0:\n",
    "        return 1.0\n",
    "    return score_loo / score_base\n",
    "\n",
    "base_dir = CONFIG[\"base_dir\"]\n",
    "base_path = os.path.join(base_dir, CONFIG[\"base_file\"])\n",
    "inputs_path = os.path.join(base_dir, CONFIG[\"inputs_file\"])\n",
    "\n",
    "df_base, prob_cols = _read_base_probs(base_path, CONFIG)\n",
    "ev_tbl = _read_evidence(inputs_path, CONFIG[\"evidence_sheet\"])\n",
    "weights = _read_weights_or_default(inputs_path, CONFIG[\"default_weights\"])\n",
    "wf, wc, wh = weights[\"weight_FDR\"], weights[\"weight_Count\"], weights[\"weight_Hub\"]\n",
    "floor = weights[\"floor\"]\n",
    "\n",
    "paths = [\"PI3K-AKT\", \"PPAR\", \"LPS\", \"ROS\"]\n",
    "\n",
    "summary_rows = []\n",
    "detail_sheets = {}\n",
    "\n",
    "for path_name in paths:\n",
    "    if path_name not in ev_tbl.index:\n",
    "        continue\n",
    "\n",
    "    prob_col = prob_cols[path_name]\n",
    "    if prob_col not in df_base.columns:\n",
    "raise ValueError(\n",
    "    f\"Baseline probability table is missing column: {prob_col} \"\n",
    "    f\"(pathway {path_name}); available columns: {list(df_base.columns)}\"\n",
    ")\n",
    "\n",
    "\n",
    "    F = float(ev_tbl.loc[path_name, \"FDR\"])\n",
    "    C = float(ev_tbl.loc[path_name, \"Count\"])\n",
    "    H = float(ev_tbl.loc[path_name, \"Hub\"])\n",
    "\n",
    "    for drop_key in [\"FDR\", \"Count\", \"Hub\"]:\n",
    "        r = _calc_r_after_drop(F, C, H, drop_key, wf, wc, wh)\n",
    "\n",
    "        base_vals = df_base[prob_col].astype(float).values\n",
    "        new_vals = np.maximum(floor, r * base_vals)\n",
    "\n",
    "        delta = new_vals - base_vals\n",
    "        abs_delta = np.abs(delta)\n",
    "        med_abs = float(np.median(abs_delta))\n",
    "        max_abs = float(np.max(abs_delta))\n",
    "\n",
    "        scen = f\"{path_name}_drop{drop_key}\"\n",
    "        df_detail = pd.DataFrame({\n",
    "            \"__PFAS__\": df_base[\"__PFAS__\"],\n",
    "            f\"{prob_col}(base)\": np.round(base_vals, CONFIG[\"round_digits\"]),\n",
    "            f\"{prob_col}({scen})\": np.round(new_vals, CONFIG[\"round_digits\"]),\n",
    "            f\"Δp({scen})\": np.round(delta, CONFIG[\"round_digits\"]),\n",
    "            f\"|Δp|({scen})\": np.round(abs_delta, CONFIG[\"round_digits\"]),\n",
    "        })\n",
    "        detail_sheets[scen] = df_detail\n",
    "\n",
    "        summary_rows.append({\n",
    "            \"Path\": path_name,\n",
    "            \"Scenario\": f\"LOO-{drop_key}\",\n",
    "            \"r_k\": round(r, CONFIG[\"round_digits\"]),\n",
    "            \"|Δp|_median\": round(med_abs, CONFIG[\"round_digits\"]),\n",
    "            \"|Δp|_max\": round(max_abs, CONFIG[\"round_digits\"]),\n",
    "        })\n",
    "\n",
    "\n",
    "out_summary_path = os.path.join(base_dir, CONFIG[\"out_summary\"])\n",
    "out_deltas_path = os.path.join(base_dir, CONFIG[\"out_deltas\"])\n",
    "\n",
    "pd.DataFrame(summary_rows).to_excel(out_summary_path, index=False)\n",
    "with pd.ExcelWriter(out_deltas_path, engine=\"xlsxwriter\") as writer:\n",
    "    for name, d in detail_sheets.items():\n",
    "        sheet = name[:31] if len(name) > 31 else name\n",
    "        d.to_excel(writer, index=False, sheet_name=sheet)\n",
    "\n",
    "print(\"LOO finish\")\n",
    "print(\"total：\", out_summary_path)\n",
    "print(\"detail：\", out_deltas_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
